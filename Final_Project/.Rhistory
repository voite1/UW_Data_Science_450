df[,c(sum(x1),sd(x2))]
?logging
x_values
install.packages("XML")
nfl_site = "http://www.usatoday.com/sports/nfl/arrests/"
nfl_html = readHTMLTable(nfl_site)
nfl_site = "http://www.usatoday.com/sports/nfl/arrests/"
library(XML)
nfl_html = readHTMLTable(nfl_site)
nfl_html = readHTMLTable(nfl_site)
nfl_html
nfl_data = nfl_html[[1]]
nfl_html
db_file = 'test_db.db'
conn = dbConnect(dbDriver("SQLite"), dbname=db_file)
dbWriteTable(conn, 'table_name', medals_data, overwrite=TRUE)
medals_data <- read.table("medals.txt", sep="\t", header=TRUE)
p = 0.75
n = 1000
?rbinom
bern_samples = rbinom(n, 1, p)
bern_sample_mean = sum(bern_samples)/length(bern_samples)
bern_sample_var = bern_sample_mean * (1-bern_sample_mean)
##--------------------------------------------
##
## Exploring Data in R (lecture 1)
##
## Class: PCE Data Science Methods Class
##
## Contains examples of:
##
## -Working with Distributions
##
## -Visually/Numerically Exploring data
##
##--------------------------------------------
##-----Exploring data Visually----
# Bernoulli (Binomial with n = 1)
p = 0.75
n = 1000
bern_samples = rbinom(n, 1, p)
bern_sample_mean = sum(bern_samples)/length(bern_samples)
bern_sample_var = bern_sample_mean * (1-bern_sample_mean)
bern_var = p*(1-p)
# Binomial
N = c(5, 25, 75)
binom_samples = lapply(N, function(x) rbinom(n, x, p))
binom_sample_means = lapply(binom_samples, mean)
binom_means = N*p
binom_sample_vars = lapply(binom_samples, var)
binom_vars = N*p*(1-p)
par(mfrow=c(2,2))
for (i in 1:3){
hist(binom_samples[[i]], main=paste(N[i],'Experiments'), freq=FALSE)
x_norm = seq(0,N[i], by = 0.025)
y_norm = dnorm(x_norm, mean=binom_means[i], sd=sqrt(binom_vars[i]))
lines(x_norm, y_norm)
}
##-------------------------------------------------
## Aleksey Kramer
## Data Science 350
## Final Project
## Analysis of Seattle Restaurant Inspection Data
##-------------------------------------------------
require(logging)
# Set working directory
#setwd('C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_350\\FinalTWITProject')
setwd('/Users/voitel/TRAINING/UW_Data_Science/UW_Data_Science_350/FinalTWITProject')
# Filename to save
f_name <- "restaurant.csv"
if(!file.exists(f_name)) {
# URL to download data from
url <- "https://data.kingcounty.gov/api/views/pph9-v8tz/rows.csv?accessType=DOWNLOAD"
# Download and save data
# FOR WINDOWS REMOVE: method = "curl"
download.file(url,destfile = f_name, method = "curl")
}
# Read data file
r_data <- read.csv(f_name, stringsAsFactors = FALSE, na.strings = "")
# Look at the names
names(r_data)
# Removing Phone data because it is irrelevant and incomplete
r_data$Phone <- NULL
# Isolate Seattle only
r_data <- r_data[r_data$City == "Seattle",]
# Remove City filed (not needed any more)
r_data$City <- NULL
# Check the dimension of the data
dim(r_data)
# Replace all N/A valuses in with "none" to save the records
r_data$Violation.Type[is.na(r_data$Violation.Type)] <- "none"
r_data$Violation.Description[is.na(r_data$Violation.Description)] <- "none"
r_data$Violation_Record_ID[is.na(r_data$Violation_Record_ID)] <- "none"
# Convert date field to Date Type
r_data$Inspection.Date <- as.Date(r_data$Inspection.Date, format = "%m/%d/%Y")
# Isolate year 2015 only (if needed)
# r_data <- r_data[r_data$Inspection.Date > '2014-12-31',]
# Try histograms on violation points (not good)
hist(r_data$Violation.Points)
# Try log of violation points (much better)
hist(log(r_data$Violation.Points))
##-------------------------------------------------
## Aleksey Kramer
## Data Science 350
## Final Project
## Analysis of Seattle Restaurant Inspection Data
##-------------------------------------------------
require(logging)
# Set working directory
#setwd('C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_350\\FinalTWITProject')
setwd('/Users/voitel/TRAINING/UW_Data_Science/UW_Data_Science_350/FinalTWITProject')
# Filename to save
f_name <- "restaurant.csv"
if(!file.exists(f_name)) {
# URL to download data from
url <- "https://data.kingcounty.gov/api/views/pph9-v8tz/rows.csv?accessType=DOWNLOAD"
# Download and save data
# FOR WINDOWS REMOVE: method = "curl"
download.file(url,destfile = f_name, method = "curl")
}
# Read data file
r_data <- read.csv(f_name, stringsAsFactors = FALSE, na.strings = "")
# Look at the names
names(r_data)
# Removing Phone data because it is irrelevant and incomplete
r_data$Phone <- NULL
# Isolate Seattle only
r_data <- r_data[r_data$City == "Seattle",]
# Remove City filed (not needed any more)
r_data$City <- NULL
# Check the dimension of the data
dim(r_data)
# Replace all N/A valuses in with "none" to save the records
r_data$Violation.Type[is.na(r_data$Violation.Type)] <- "none"
r_data$Violation.Description[is.na(r_data$Violation.Description)] <- "none"
r_data$Violation_Record_ID[is.na(r_data$Violation_Record_ID)] <- "none"
# Convert date field to Date Type
r_data$Inspection.Date <- as.Date(r_data$Inspection.Date, format = "%m/%d/%Y")
# Isolate year 2015 only (if needed)
# r_data <- r_data[r_data$Inspection.Date > '2014-12-31',]
# cleanup
rm(f_name)
rm(url)
# Try histograms on violation points (not good)
hist(r_data$Violation.Points)
# Try log of violation points (much better)
hist(log(r_data$Violation.Points))
View(r_data)
View(r_data)
unique(r_data$Inspection.Type)
r_data[r_data$Inspection.Type == 'Consultation/Education - Field']
r_data[r_data$Inspection.Type == 'Consultation/Education - Field',]
r_data[r_data$Inspection.Type == 'Consultation/Education - Field',]$my_inspection.type <- 1
r_data[r_data$Inspection.Type == 'Consultation/Education - Field',] <- 1
r_data$my_InspectionType[r_data$Inspection.Type == 'Consultation/Education - Field',] <- 1
r_data$my_InspectionType[r_data$Inspection.Type == 'Consultation/Education - Field'] <- 1
unique(r_data$Inspection.Type)
r_data$my_InspectionType[r_data$Inspection.Type == 'Return Inspection'] <- 3
r_data$my_InspectionType[r_data$Inspection.Type == 'Routine Inspection/Field Review'] <- 2
unique(r_data$Violation.Type)
r_data$my_ViolationType[r_data$Violation.Type == 'none'] <- 1
r_data$my_ViolationType[r_data$Violation.Type == 'blue'] <- 2
r_data$my_ViolationType[r_data$Violation.Type == 'red'] <- 3
distinct(r_data$Inspection.Score)
unique(r_data$Inspection.Score)
unique(r_data$Violation.Points)
hist(r_data$Violation.Points)
unique(r_data$Longitude)
unique(r_data$Latitude)
hist(r_data$Violation.Points)
hist(r_data$Violation.Description)
hist(r_data$Inspection.Score)
hist(log(r_data$Inspection.Score))
save.image("~/TRAINING/UW_Data_Science/UW_Data_Science_350/Final_Project/Untitled.RData")
##-------------------------------------------------
## Aleksey Kramer
## Data Science 350
## Final Project
## Analysis of Seattle Restaurant Inspection Data
##-------------------------------------------------
require(logging)
# Set working directory
#setwd('C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_350\\FinalTWITProject')
setwd('/Users/voitel/TRAINING/UW_Data_Science/UW_Data_Science_350/FinalTWITProject')
# Filename to save
f_name <- "restaurant.csv"
if(!file.exists(f_name)) {
# URL to download data from
url <- "https://data.kingcounty.gov/api/views/pph9-v8tz/rows.csv?accessType=DOWNLOAD"
# Download and save data
# FOR WINDOWS REMOVE: method = "curl"
download.file(url,destfile = f_name, method = "curl")
}
# Read data file
r_data <- read.csv(f_name, stringsAsFactors = FALSE, na.strings = "")
# Look at the names
names(r_data)
# Removing Phone data because it is irrelevant and incomplete
r_data$Phone <- NULL
# Isolate Seattle only
r_data <- r_data[r_data$City == "Seattle",]
# Remove City filed (not needed any more)
r_data$City <- NULL
# Check the dimension of the data
dim(r_data)
# Replace all N/A valuses in with "none" to save the records
r_data$Violation.Type[is.na(r_data$Violation.Type)] <- "none"
r_data$Violation.Description[is.na(r_data$Violation.Description)] <- "none"
r_data$Violation_Record_ID[is.na(r_data$Violation_Record_ID)] <- "none"
# Convert date field to Date Type
r_data$Inspection.Date <- as.Date(r_data$Inspection.Date, format = "%m/%d/%Y")
# cleanup unused variables
rm(f_name)
rm(url)
# Add numeric equivalelnt of Inspection Type column to r_data data frame
unique(r_data$Inspection.Type)
r_data$my_InspectionType[r_data$Inspection.Type == 'Consultation/Education - Field'] <- 1
r_data$my_InspectionType[r_data$Inspection.Type == 'Routine Inspection/Field Review'] <- 2
r_data$my_InspectionType[r_data$Inspection.Type == 'Return Inspection'] <- 3
# Add numeric equivalient of Violation Type ro r_data data frame
unique(r_data$Violation.Type)
r_data$my_ViolationType[r_data$Violation.Type == 'none'] <- 1
r_data$my_ViolationType[r_data$Violation.Type == 'blue'] <- 2
r_data$my_ViolationType[r_data$Violation.Type == 'red'] <- 3
# Try using Longtitude, Lattitude, log(inspection score), and log(violation points) to run statistics
unique(r_data$Longitude)
length(unique(r_data$Longitude))
lendth(r_data$Longitude)
length(r_data$Longitude)
str(r_data)
hist(r_data$Longitude)
hist(r_data$Longitude)
require(logging)
require(nortest)
install.packages("nortest")
install.packages("nortest")
require(nortest)
# Set working directory
setwd('C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_350\\FinalTWITProject')
# setwd('/Users/voitel/TRAINING/UW_Data_Science/UW_Data_Science_350/FinalTWITProject')
# Filename to save
f_name <- "restaurant.csv"
if(!file.exists(f_name)) {
# URL to download data from
url <- "https://data.kingcounty.gov/api/views/pph9-v8tz/rows.csv?accessType=DOWNLOAD"
# Download and save data
# For Mac
# download.file(url,destfile = f_name, method = "curl")
# For Windows
download.file(url,destfile = f_name)
}
# Read data file
r_data <- read.csv(f_name, stringsAsFactors = FALSE, na.strings = "")
# Look at the names
names(r_data)
# Removing Phone data because it is irrelevant and incomplete
r_data$Phone <- NULL
# Isolate Seattle only
r_data <- r_data[r_data$City == "Seattle",]
# Remove City filed (not needed any more)
r_data$City <- NULL
# Check the dimension of the data
dim(r_data)
# Replace all N/A valuses in with "none" to save the records
r_data$Violation.Type[is.na(r_data$Violation.Type)] <- "none"
r_data$Violation.Description[is.na(r_data$Violation.Description)] <- "none"
r_data$Violation_Record_ID[is.na(r_data$Violation_Record_ID)] <- "none"
# Convert date field to Date Type
r_data$Inspection.Date <- as.Date(r_data$Inspection.Date, format = "%m/%d/%Y")
# cleanup unused variables
rm(f_name)
rm(url)
# Add numeric equivalelnt of Inspection Type column to r_data data frame
unique(r_data$Inspection.Type)
r_data$my_InspectionType[r_data$Inspection.Type == 'Consultation/Education - Field'] <- 1
r_data$my_InspectionType[r_data$Inspection.Type == 'Routine Inspection/Field Review'] <- 2
r_data$my_InspectionType[r_data$Inspection.Type == 'Return Inspection'] <- 3
# Add numeric equivalient of Violation Type ro r_data data frame
unique(r_data$Violation.Type)
r_data$my_ViolationType[r_data$Violation.Type == 'none'] <- 1
r_data$my_ViolationType[r_data$Violation.Type == 'blue'] <- 2
r_data$my_ViolationType[r_data$Violation.Type == 'red'] <- 3
# Check Longtitude and Lattitude variables for Normality
var_longt <- ad.test(r_data$Longitude)
var_latt <- ad.test(r_data$Latitude)
# Output p-value for Longtitute and Lattitude variables (both of them
# are normally distributed).  Paremetric tests should be used.
print(paste('p-value for normality test of Longtitude variable is:', var_longt$p.value))
print(paste('p-value for normality test of Lattitude variable is:', var_latt$p.value))
# Try using Longtitude, Lattitude to run statistics against my_inspectionType and my_ViolationType
url <- "https://data.kingcounty.gov/api/views/pph9-v8tz/rows.csv?accessType=DOWNLOAD"
rm(url)
rm(var_latt)
rm(var_longt)
install.packages(c("prodlim", "RcppArmadillo", "splancs"))
princomp()
aris
iris
princomp(iris[,-5])
fit <- princomp(iris[,-5])
summary(fit)
fit$sdev
fit$sdev[,1]
fit$sdev[,"Comp.1"]
fit$sdev["Comp.1"]
fit$sdev[1]
fit$sdev[1]$name
str(fit$sdev[1])
acf?
c
v
?acf
?arima
?stl
# Update the working directory for the place on your computer where you store the project
setwd('/Users/voitel/TRAINING/UW_Data_Science/UW_Data_Science_450/Final_Project')
# setwd('C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_450\\Final_Project')
# Designate file name for the download data
file.name = "data.csv"
# Variabled to hold data frame created from downloaded file named file.name
data = ""
# Usage of the local file named data.csv is preferred. If data is not available, usage of Mac is preferred.
if(!file.exists(file.name)) {
# works on Mac only. R cannot download HTTPS links on windows any more
print("Downloading data file")
download.file("https://www.dropbox.com/s/xnsl4d6u3c3oper/train.csv?dl=0", destfile = file.name, method = "curl")
Print("Data file downloaded")
} else {
# read CSV file in memory
print("Data file exists, reading data file in memory")
data = read.csv(file.name)
}
# Extract Complete Cases (removed 4229 records)
print("Removing incomplete records")
data = data[complete.cases(data),]
print("Firinshed removing incomplete records")
# Remove duplicate rows (removed 4443 records)
print("Removing duplicate records")
data = data[!duplicated(data), ]
print("Finished removing duplicate records")
# Add weekend column (0 - workday, 1 - Weekend)
print("Started creating 'Weekend' column" )
data$Weekend = 0
data[data$Weekday=="Saturday",]$Weekend = 1
data[data$Weekday=="Sunday",]$Weekend = 1
print("Finished creating 'Weekend' column")
# Update the working directory for the place on your computer where you store the project
setwd('/Users/voitel/TRAINING/UW_Data_Science/UW_Data_Science_450/Final_Project')
# setwd('C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_450\\Final_Project')
# Designate file name for the download data
file.name = "data.csv"
# Variabled to hold data frame created from downloaded file named file.name
data = ""
# Usage of the local file named data.csv is preferred. If data is not available, usage of Mac is preferred.
if(!file.exists(file.name)) {
# works on Mac only. R cannot download HTTPS links on windows any more
print("Downloading data file")
download.file("https://www.dropbox.com/s/xnsl4d6u3c3oper/train.csv?dl=0", destfile = file.name, method = "curl")
Print("Finished downloading data file")
print("Reading data in memory")
data = read.csv(file.name)
print("Finished loading data in memory")
} else {
# read CSV file in memory
print("Data file exists, reading data file in memory")
data = read.csv(file.name)
print("Finished reading file in memory")
}
# Extract Complete Cases (removed 4229 records)
print("Removing incomplete records")
data = data[complete.cases(data),]
print("Firinshed removing incomplete records")
# Remove duplicate rows (removed 4443 records)
print("Removing duplicate records")
data = data[!duplicated(data), ]
print("Finished removing duplicate records")
# Add weekend column (0 - workday, 1 - Weekend)
print("Started creating 'Weekend' column" )
data$Weekend = 0
data[data$Weekday=="Saturday",]$Weekend = 1
data[data$Weekday=="Sunday",]$Weekend = 1
print("Finished creating 'Weekend' column")
# Update the working directory for the place on your computer where you store the project
setwd('/Users/voitel/TRAINING/UW_Data_Science/UW_Data_Science_450/Final_Project')
# setwd('C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_450\\Final_Project')
# Designate file name for the download data
file.name = "data.csv"
# Variabled to hold data frame created from downloaded file named file.name
data = ""
# Usage of the local file named data.csv is preferred. If data is not available, usage of Mac is preferred.
if(!file.exists(file.name)) {
# works on Mac only. R cannot download HTTPS links on windows any more
print("Downloading data file")
download.file("https://www.dropbox.com/s/xnsl4d6u3c3oper/train.csv?dl=0", destfile = file.name, method = "curl")
Print("Finished downloading data file")
print("Reading data in memory")
data = read.csv(file.name)
print("Finished loading data in memory")
} else {
# read CSV file in memory
print("Data file exists, reading data file in memory")
data = read.csv(file.name)
print("Finished reading file in memory")
}
# Extract Complete Cases (removed 4229 records)
# Update the working directory for the place on your computer where you store the project
setwd('/Users/voitel/TRAINING/UW_Data_Science/UW_Data_Science_450/Final_Project')
# setwd('C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_450\\Final_Project')
# Designate file name for the download data
file.name = "data.csv"
# Variabled to hold data frame created from downloaded file named file.name
data = ""
# Usage of the local file named data.csv is preferred. If data is not available, usage of Mac is preferred.
if(!file.exists(file.name)) {
# works on Mac only. R cannot download HTTPS links on windows any more
print("Downloading data file")
download.file("https://www.dropbox.com/s/xnsl4d6u3c3oper/train.csv?dl=0", destfile = file.name, method = "curl")
print("Finished downloading data file")
print("Reading data in memory")
data = read.csv(file.name)
print("Finished loading data in memory")
} else {
# read CSV file in memory
print("Data file exists, reading data file in memory")
data = read.csv(file.name)
print("Finished reading file in memory")
}
# Extract Complete Cases (removed 4229 records)
print("Removing incomplete records")
data = data[complete.cases(data),]
print("Firinshed removing incomplete records")
# Remove duplicate rows (removed 4443 records)
print("Removing duplicate records")
data = data[!duplicated(data), ]
print("Finished removing duplicate records")
# Add weekend column (0 - workday, 1 - Weekend)
print("Started creating 'Weekend' column" )
data$Weekend = 0
data[data$Weekday=="Saturday",]$Weekend = 1
data[data$Weekday=="Sunday",]$Weekend = 1
print("Finished creating 'Weekend' column")
# Update the working directory for the place on your computer where you store the project
setwd('/Users/voitel/TRAINING/UW_Data_Science/UW_Data_Science_450/Final_Project')
# setwd('C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_450\\Final_Project')
# Designate file name for the download data
file.name = "data.csv"
# Usage of the local file named data.csv is preferred. If data is not available, usage of Mac is preferred.
if(!file.exists(file.name)) {
# works on Mac only. R cannot download HTTPS links on windows any more
print("Downloading data file")
download.file("https://www.dropbox.com/s/xnsl4d6u3c3oper/train.csv?dl=0", destfile = file.name, method = "curl")
print("Finished downloading data file")
print("Reading data in memory")
data = read.csv(file.name)
print("Finished loading data in memory")
} else {
# read CSV file in memory
print("Data file exists, reading data file in memory")
data = read.csv(file.name)
print("Finished reading file in memory")
}
# Extract Complete Cases (removed 4229 records)
print("Removing incomplete records")
data = data[complete.cases(data),]
print("Firinshed removing incomplete records")
# Remove duplicate rows (removed 4443 records)
print("Removing duplicate records")
data = data[!duplicated(data), ]
print("Finished removing duplicate records")
# Add weekend column (0 - workday, 1 - Weekend)
print("Started creating 'Weekend' column" )
data$Weekend = 0
data[data$Weekday=="Saturday",]$Weekend = 1
data[data$Weekday=="Sunday",]$Weekend = 1
print("Finished creating 'Weekend' column")
source('~/TRAINING/UW_Data_Science/UW_Data_Science_450/Final_Project/Team_T10_Final_Project.R')
# Update the working directory for the place on your computer where you store the project
setwd('/Users/voitel/TRAINING/UW_Data_Science/UW_Data_Science_450/Final_Project')
# setwd('C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_450\\Final_Project')
# Designate file name for the download data
file.name = "data.csv"
# Usage of the local file named data.csv is preferred. If data is not available, usage of Mac is preferred.
if(!file.exists(file.name)) {
# works on Mac only. R cannot download HTTPS links on windows any more
print("Downloading data file")
download.file("https://www.dropbox.com/s/xnsl4d6u3c3oper/train.csv?dl=0", destfile = file.name, method = "curl")
print("Finished downloading data file")
print("Reading data in memory")
data = read.csv(file.name)
print("Finished loading data in memory")
} else {
# read CSV file in memory
print("Data file exists, reading data file in memory")
data = read.csv(file.name)
print("Finished reading file in memory")
}
# Extract Complete Cases (removed 4229 records)
print("Removing incomplete records")
data = data[complete.cases(data),]
print("Firinshed removing incomplete records")
# Remove duplicate rows (removed 4443 records)
print("Removing duplicate records")
data = data[!duplicated(data), ]
print("Finished removing duplicate records")
# Add weekend column (0 - workday, 1 - Weekend)
print("Started creating 'Weekend' column" )
data$Weekend = 0
data[data$Weekday=="Saturday",]$Weekend = 1
data[data$Weekday=="Sunday",]$Weekend = 1
print("Finished creating 'Weekend' column")
# Clean workspace, remove variable that holds file name
rm(file.name)
